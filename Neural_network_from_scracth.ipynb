{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9n5IfFKNoGKL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RX0CIz7qoOLx"
   },
   "outputs": [],
   "source": [
    "!python3 dlc_practical_prologue.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V9FXHxRg_fRx"
   },
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6KWaFalK_xGv"
   },
   "source": [
    "##  Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3LDYdsGt_zC_"
   },
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    x = torch.tanh(x)\n",
    "    return x\n",
    "\n",
    "def dsigma(b):\n",
    "    y = sigma(b)\n",
    "    c = 1 - y.pow(2)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YgFyT5ECColQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6G2ku2nCwzU"
   },
   "source": [
    "##  Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-7m-M2iCy9u"
   },
   "outputs": [],
   "source": [
    "def loss(v,t):\n",
    "    a = torch.sub(v,t) \n",
    "    a = a.pow(2).sum()\n",
    "    return a\n",
    "\n",
    "\n",
    "def dloss(v,t):\n",
    "    a = 2*(v-t)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ra-JyssmEGGm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCf8gwfRE42w"
   },
   "source": [
    "## forward and backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X13AKRW5E97F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TVJwPFLXFMsR"
   },
   "outputs": [],
   "source": [
    "\n",
    "def forward_pass(x,w1,w2,b1,b2):\n",
    "    x0 = x\n",
    "    s1  = w1.mv(x0)+ b1\n",
    "    x1 = sigma(s1)\n",
    "    s2  = w2.mv(x1) + b2 \n",
    "    x2 = sigma(s2)\n",
    "    return x0,s1,x1,s2,x2\n",
    "\n",
    "\n",
    "def back_ward_pass(w1,b1,w2,b2,t,s1,x,x1,s2,x2,dl_w1,dl_b1,dl_w2,dl_b2):\n",
    "    dl_x2 = dloss(x2,t)\n",
    "    dl_s2 = dl_x2 * dsigma(s2)\n",
    "    dl_x1 = w2.t().mv(dl_s2)\n",
    "    dl_s1 = dsigma(s1) * dl_x1\n",
    "\n",
    "    \n",
    "\n",
    "    dl_w2.add_(dl_s2.view(-1,1).mm(x1.view(1,-1)))\n",
    "    dl_b2.add_(dl_s2)\n",
    "    \n",
    "    dl_w1.add_(dl_s1.view(-1,1).mm(x.view(1,-1)))\n",
    "    dl_b1.add_(dl_s1)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gdfvke4zMT0K"
   },
   "source": [
    "## training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 908,
     "status": "error",
     "timestamp": 1579697726865,
     "user": {
      "displayName": "Moteu Ngoli Tatiana",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBFJb5RJm3wz-OgFnI9ZXDhrht3OEuszct5id4C=s64",
      "userId": "01422268200443282511"
     },
     "user_tz": 0
    },
    "id": "DeaEQ_2JMXFX",
    "outputId": "2962a9f3-4b2b-4c54-d33a-34e1a8c49ea8"
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aims/.local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/home/aims/.local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/home/aims/.local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/aims/.local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "train_input,train_target,test_input,test_target=prologue.load_data(one_hot_labels=True,normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = train_input * 0.9\n",
    "test_input = test_input * 0.9\n",
    "train_target = train_target * 0.9\n",
    "test_target = test_target * 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vvYA0rsN3PJ"
   },
   "outputs": [],
   "source": [
    "# create the weight and bias\n",
    "hidden=50\n",
    "size_output=10\n",
    "epsilon=1e-6\n",
    "w1 = torch.empty(hidden,train_input.size(1)).normal_(0,epsilon)\n",
    "w2 = torch.empty(size_output,hidden).normal_(0,epsilon)\n",
    "b1 = torch.empty(hidden).normal_(0,epsilon)\n",
    "b2 = torch.empty(size_output).normal_(0,epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "izyT0y2vQOzj"
   },
   "outputs": [],
   "source": [
    "#create the four tensor\n",
    "dl_w1 = torch.empty(w1.size())\n",
    "dl_w2 = torch.empty(w2.size())\n",
    "dl_b1 = torch.empty(b1.size())\n",
    "dl_b2 = torch.empty(b2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train_input[0]\n",
    "#forward_pass(x,w1,w2,b1,b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = forward_pass(x,w1,w2,b1,b2)[2]\n",
    "x2 = forward_pass(x,w1,w2,b1,b2)[4]\n",
    "s1 = forward_pass(x,w1,w2,b1,b2)[1]\n",
    "s2 = forward_pass(x,w1,w2,b1,b2)[3]\n",
    "t = train_target[0]\n",
    "back_ward_pass(w1,b1,w2,b2,t,s1,x,x1,s2,x2,dl_w1,dl_b1,dl_w2,dl_b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.1 / train_input.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = []\n",
    "for epoch in range(epochs):\n",
    "    dl_w1.zero_()\n",
    "    dl_w2.zero_()\n",
    "    dl_b1.zero_()\n",
    "    dl_b2.zero_()\n",
    "    train_errors = 0\n",
    "    for i in range(train_input.size(0)):\n",
    "        x = train_input[i]\n",
    "        t = train_target[i]\n",
    "        accuracy = 0\n",
    "    \n",
    "        x0,s1,x1,s2,x2 = forward_pass(x,w1,w2,b1,b2)\n",
    "        #print(x2)\n",
    "        #print(loss(x2,t))\n",
    "        train_errors+= loss(x2,t)\n",
    "        \n",
    "        back_ward_pass(w1,b1,w2,b2,t,s1,x,x1,s2,x2,dl_w1,dl_b1,dl_w2,dl_b2)\n",
    "     \n",
    "    w1 = w1 - lr * dl_w1\n",
    "    w2 = w2 - lr * dl_w2\n",
    "    b1 = b1 - lr * dl_b1\n",
    "    b2 = b2 - lr * dl_b2\n",
    "    train_error.append(int(train_errors) / train_input.size(0))    \n",
    "    #print(\"train_errors{}\".format(train_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6d24e79780>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 784])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction = torch.zeros(size=(1000,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(Prediction.size(0)):\n",
    "    x = test_input[k]\n",
    "    _,_,_,_,x2 = forward_pass(x,w1,w2,b1,b2)\n",
    "    \n",
    "    Prediction[k,:] = x2\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.argmax(test_target,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.argmax(Prediction,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(int(sum(test==pred)) / pred.size(0)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aims/.local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/home/aims/.local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/home/aims/.local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/aims/.local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = \\\n",
    "    prologue.load_data(one_hot_labels = True, normalize = True, flatten = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(256, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,train_input,train_target, mini_batch_size=100):\n",
    "    \n",
    "    train_input, train_target = Variable(train_input), Variable(train_target)\n",
    "\n",
    "    model, criterion = Net(), nn.MSELoss()\n",
    "    eta = 1e-1\n",
    "\n",
    "    for e in range(0, 25):\n",
    "        sum_loss = 0\n",
    "        # We do this with mini-batches\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            for p in model.parameters():\n",
    "                p.data.sub_(eta * p.grad.data)\n",
    "        print(e, sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9317096769809723\n",
      "1 0.8004817217588425\n",
      "2 0.7303637638688087\n",
      "3 0.6706141084432602\n",
      "4 0.6184233389794827\n",
      "5 0.5737861730158329\n",
      "6 0.5374620966613293\n",
      "7 0.5120180286467075\n",
      "8 0.5020802095532417\n",
      "9 0.467223834246397\n",
      "10 0.43965745344758034\n",
      "11 0.4230715185403824\n",
      "12 0.4242453761398792\n",
      "13 0.4068593233823776\n",
      "14 0.37808458134531975\n",
      "15 0.3920299708843231\n",
      "16 0.357477106153965\n",
      "17 0.33990385197103024\n",
      "18 0.3309630714356899\n",
      "19 0.32369043305516243\n",
      "20 0.31674420461058617\n",
      "21 0.3086628057062626\n",
      "22 0.2963087745010853\n",
      "23 0.2845682445913553\n",
      "24 0.30947767943143845\n"
     ]
    }
   ],
   "source": [
    "model= Net()\n",
    "train_model(model,train_input,train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_nb_errors(model,test_input, test_target, mini_batch_size = 100):\n",
    "     \n",
    "    test_input, test_target = Variable(test_input), Variable(test_target)\n",
    "\n",
    "\n",
    "    accuracy_list = []\n",
    "    for t in range(0, test_input.size(0),mini_batch_size):\n",
    "        output = model(test_input.narrow(0, t, mini_batch_size))\n",
    "        target = test_target.narrow(0, t, mini_batch_size)\n",
    "        pred = torch.tensor([int(torch.argmax(output[i])) for i in range(len(output))])\n",
    "\n",
    "        correct = torch.tensor([int(torch.argmax(target[i])) for i in range(len(target))])\n",
    "\n",
    "        accuracy =(((pred == correct) *1.0).mean()) * 100\n",
    "        accuracy_list.append(accuracy)\n",
    "        maxL = max(accuracy_list)\n",
    "    print (float(accuracy),float(maxL))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 16.0\n"
     ]
    }
   ],
   "source": [
    "compute_nb_errors(model,test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(64,32, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(, 200)\n",
    "        self.fc2 = nn.Linear(200, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x), kernel_size=1, stride=1))\n",
    "        x = F.relu(self.fc1(x.view(-1, 512)))\n",
    "        x = F.relu(self.fc2(x.view(-1, 200)))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNQHuw3thKM90OqhBbVErh0",
   "collapsed_sections": [],
   "name": "tutorial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
